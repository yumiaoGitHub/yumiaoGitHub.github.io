---
layout:     post
title:      集成学习-双流融合
subtitle:   多模态信息融合
date:       2018-03-23
author:     Mily
header-img: img/post-bg-cook.jpg
catalog: true
tags:
- 算法
    - action recognition
---


集成学习：构建多个分类器（弱分类器）用某种策略将多个结果集成起来作为最终结果。

要求：每个弱分类器具备一定的“准确性”，分类器之间具备“差异性”——**好而不同**

## 集成学习分类

1）基分类器之间无强依赖，可**并行**：Bagging、随机森林（Random Forest）

2）基分类器之间强依赖，必须**串行**：Boosting   

**1、Bagging** 

（bootstrap aggregating）自举汇聚法——**有放回地采样数据**

- 从原始样本集中抽取训练集。每轮从原始样本集中使用Bootstraping的方法抽取n个训练样本（在训练集中，有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中）。共进行k轮抽取，得到k个训练集。（k个训练集之间是相互独立的）
- 每次使用一个训练集得到一个模型，k个训练集共得到k个模型。（注：这里并没有具体的分类算法或回归方法，我们可以根据具体问题采用不同的分类或回归方法，如决策树、感知器等）
- 对分类问题：将上步得到的k个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果。**（所有模型的重要性相同）**

![clipboard(1)](/../img/2018-03-23-集成学习-双流融合/clipboard(1).png)

### **2、Boosting**

（re-weighting）**重赋权**法迭代地训练基分类器

- 每一轮的训练数据样本赋予一个权重，并且每一轮样本的权值分布依赖上一轮的分类结果。
- 基分类器之间采用序列式的线性加权方式进行组合。

![ml_10_2](/../img/2018-03-23-集成学习-双流融合/ml_10_2.png)

|              | **Bagging**      | **Boosting**             |
| ------------ | ---------------- | ------------------------ |
| **样本选择** | 有放回           | 不变                     |
| **样例权重** | 均匀取样权重相等 | 错误率越大则权重越大     |
| **预测函数** | 权重相等         | 分类误差小的分类器权重大 |

## **投票法**

![clipboard](/../img/2018-03-23-集成学习-双流融合/clipboard.png)

常用的分类器“加法”有以下几种：

- 求和，Di的和；
- 加权和：每个学习器的权重需要事先指定或者训练学习得到
- 中位数：对离群点更鲁棒；
- 最值：最小和最大分别是悲观和乐观的估计；
- 乘积：每个学习器都有否决权；

### **层叠泛化（stacked generalization）**

其实也是*投票*的一种扩展，因为投票系统的组合方式大多是线性的，而层叠泛化则不一定如此，组合方式可以是一个单独的复杂的学习器。比如：

![cc3wieq](/../img/2018-03-23-集成学习-双流融合/cc3wieq.png)

组合系统F(*|φ )可以是线性的，也可是非线性的，也可以是一个单独的学习器，比如是一个多层感知器，参数φ是连接权重。

## **总结思考**

- 将RGB分类器和flow分类器作为基学习器

- 采用层叠泛化方式，取长补短

- 不同的行为类别有不同的权重（动静结合）